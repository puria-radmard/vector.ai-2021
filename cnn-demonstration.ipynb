{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "import torch\n",
                "\n",
                "from cnn.utils import *\n",
                "from cnn.train import train\n",
                "from cnn.model import generate_model_by_name"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "default_fashion_mnist_convnet = generate_model_by_name(\n",
                "    num_classes=10, input_size=[1, 28, 28], name=\"default\"\n",
                ")\n",
                "print(default_fashion_mnist_convnet)\n",
                "default_fashion_mnist_convnet(torch.randn(64, 1, 28, 28)).shape"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "ConvNN(\n",
                        "  (convolutional_layers): Sequential(\n",
                        "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
                        "    (1): ReluLayer()\n",
                        "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
                        "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
                        "    (4): ReluLayer()\n",
                        "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
                        "  )\n",
                        "  (flatten): FlattenLayer()\n",
                        "  (fc_layers): Sequential(\n",
                        "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
                        "    (1): Linear(in_features=120, out_features=84, bias=True)\n",
                        "    (2): ReluLayer()\n",
                        "    (3): Linear(in_features=84, out_features=10, bias=True)\n",
                        "  )\n",
                        ")\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "torch.Size([64, 10])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "train_data = torch.randn(60000, 1, 28, 28)\n",
                "eval_data = torch.randn(10000, 1, 28, 28)\n",
                "train_labels = torch.randint(0, 10, [60000])\n",
                "eval_labels = torch.randint(0, 10, [10000])\n",
                "\n",
                "train_dataset = SimpleImageDataset(train_data, train_labels)\n",
                "eval_dataset = SimpleImageDataset(eval_data, eval_labels)\n",
                "\n",
                "train_dataloader = torch.utils.data.DataLoader(train_dataset, collate_fn=coll_fn, batch_size=32, shuffle=True)\n",
                "eval_dataloader = torch.utils.data.DataLoader(eval_dataset, collate_fn=coll_fn, batch_size=32)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "source": [
                "import time\n",
                "\n",
                "waittimes = (abs(5*torch.randn(700)).int() + 5).cpu().numpy()\n",
                "for wtime in waittimes:\n",
                "    for t in list(range(wtime))[::-1]:\n",
                "        print(f\"Next image in {t}\", end='\\r')\n",
                "        time.sleep(1)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": []
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-34-548c36a6c42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Next image in {t}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "criterion = torch.nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(default_fashion_mnist_convnet.parameters())\n",
                "\n",
                "dummy_model = train(default_fashion_mnist_convnet, criterion, optimizer, train_dataloader, eval_dataloader, 1)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "1875it [00:10, 173.87it/s]\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 0: train loss 0.07197631508111954, train accuracy 0.09971666666666666\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "313it [00:00, 427.49it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 0: test loss 0.07208316776752471, test accuracy 0.0981\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('container': conda)"
        },
        "interpreter": {
            "hash": "3055f3e12c0e234810da0dad9021fc400e0b7cf6c5f76517be4bba87130b6d4e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}